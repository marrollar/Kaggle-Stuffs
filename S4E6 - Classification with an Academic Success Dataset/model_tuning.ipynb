{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import umap\n",
    "import datetime\n",
    "import optuna\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, label_binarize, PolynomialFeatures, RobustScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import r2_score, accuracy_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import xgboost\n",
    "\n",
    "import gc\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\", index_col=0)\n",
    "test_df = pd.read_csv(\"data/test.csv\", index_col=0)\n",
    "original_df = pd.read_csv(\"data/original.csv\",sep=\";\")\n",
    "train_features = test_df.columns\n",
    "\n",
    "cat_features = ['Marital status', 'Application mode', 'Course',\n",
    "                'Previous qualification', 'Nacionality', \"Mother's qualification\", \n",
    "                \"Father's qualification\", \"Mother's occupation\",\n",
    "                \"Father's occupation\"]\n",
    "cont_features = list(set(train_features).difference(cat_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in cat_features:\n",
    "    dtype = pd.CategoricalDtype(categories=list(set(train_df[feat]) | set(test_df[feat]) | set(original_df[feat])), ordered=False)\n",
    "    for df in [train_df, test_df, original_df]:\n",
    "        df[feat] = df[feat].astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_df, test_df, original_df]:\n",
    "    df[\"Misery Index\"] = df[\"Unemployment rate\"] + df[\"Inflation rate\"]\n",
    "    # df[\"Economic Discomfort\"] = df[\"Misery Index\"] - df[\"GDP\"]\n",
    "\n",
    "cont_features.append(\"Misery Index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_order = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"Curricular units 2nd sem (approved)\": 0.5262597,\n",
    "        \"Tuition fees up to date\": 0.12040115,\n",
    "        \"Scholarship holder\": 0.04374109,\n",
    "        \"Curricular units 1st sem (approved)\": 0.043124773,\n",
    "        \"Curricular units 2nd sem (enrolled)\": 0.034864154,\n",
    "        \"Curricular units 2nd sem (evaluations)\": 0.033007413,\n",
    "        \"Curricular units 1st sem (evaluations)\": 0.026952056,\n",
    "        \"Debtor\": 0.02125777,\n",
    "        \"Curricular units 2nd sem (grade)\": 0.017488716,\n",
    "        \"Gender\": 0.015914941,\n",
    "        \"Age at enrollment\": 0.009499201,\n",
    "        \"Daytime/evening attendance\": 0.009322386,\n",
    "        \"Curricular units 1st sem (enrolled)\": 0.008687382,\n",
    "        \"Curricular units 2nd sem (credited)\": 0.008607062,\n",
    "        \"Course\": 0.008552427,\n",
    "        \"Mother's occupation\": 0.0074276286,\n",
    "        \"Application mode\": 0.007248743,\n",
    "        \"GDP\": 0.0058370973,\n",
    "        \"Curricular units 1st sem (grade)\": 0.00579759,\n",
    "        \"Unemployment rate\": 0.0038729862,\n",
    "        \"Mother's qualification\": 0.0035413294,\n",
    "        \"Displaced\": 0.0034240438,\n",
    "        \"Previous qualification\": 0.0033880775,\n",
    "        \"Father's occupation\": 0.0033660706,\n",
    "        \"Curricular units 1st sem (credited)\": 0.0032424054,\n",
    "        \"Admission grade\": 0.0031858524,\n",
    "        \"Curricular units 1st sem (without evaluations)\": 0.0031376902,\n",
    "        \"Marital status\": 0.0027686018,\n",
    "        \"Father's qualification\": 0.002645827,\n",
    "        \"Nacionality\": 0.0026041167,\n",
    "        \"Application order\": 0.0025012011,\n",
    "        \"Previous qualification (grade)\": 0.0024294835,\n",
    "        \"Inflation rate\": 0.0023359724,\n",
    "        \"International\": 0.0020073373,\n",
    "        \"Curricular units 2nd sem (without evaluations)\": 0.0015576994,\n",
    "    },\n",
    "    orient=\"index\",\n",
    "    columns=[\"val\"],\n",
    ")\n",
    "\n",
    "low_freq_cols = [\n",
    "    \"Nacionality\",\n",
    "    \"Educational special needs\",\n",
    "    \"International\",\n",
    "    \"Curricular units 1st sem (credited)\",\n",
    "    \"Curricular units 1st sem (without evaluations)\",\n",
    "    \"Curricular units 2nd sem (credited)\",\n",
    "    \"Curricular units 2nd sem (without evaluations)\",\n",
    "]\n",
    "\n",
    "\n",
    "# class PolynomialFeatures_DF(object):\n",
    "#     def __init__(\n",
    "#         self, degree=2, *, interaction_only=False, include_bias=True, order=\"C\"\n",
    "#     ):\n",
    "#         self.poly_feats = PolynomialFeatures(\n",
    "#             degree,\n",
    "#             interaction_only=interaction_only,\n",
    "#             include_bias=include_bias,\n",
    "#             order=order,\n",
    "#         )\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self.poly_feats.fit(X)\n",
    "\n",
    "#     def transform(self, X):\n",
    "#         X_poly = self.poly_feats.transform(X)\n",
    "#         col_names = self.poly_feats.get_feature_names_out()\n",
    "\n",
    "#         return pd.DataFrame(X_poly, columns=col_names)\n",
    "\n",
    "#     def get_params(self, deep=True):\n",
    "#         return self.poly_feats.get_params(deep=deep)\n",
    "\n",
    "class ObjectiveCV(object):\n",
    "    def __init__(self, train_set, orig_set, kfold, n_jobs, random_state=0):\n",
    "        self.train = train_set\n",
    "        self.orig = orig_set\n",
    "        self.kfold = kfold\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "        self.random_state = random_state\n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "    def __include_orig(self, inp_df):\n",
    "        return pd.concat([inp_df, self.orig], axis=0)\n",
    "\n",
    "    def __prune_low_freq(self, inp_df):\n",
    "        return inp_df.drop(columns=low_freq_cols, errors=\"ignore\")\n",
    "\n",
    "    def __prune_low_importance(self, trial, inp_df):\n",
    "        prune_thresh = trial.suggest_float(\"prune_thresh\", 0, 0.5, step=0.001)\n",
    "        pruned_cols = list(\n",
    "            feature_importances_order.loc[\n",
    "                feature_importances_order[\"val\"] < prune_thresh\n",
    "            ].index\n",
    "        )\n",
    "        return inp_df.drop(columns=pruned_cols, errors=\"ignore\")\n",
    "\n",
    "    def __model_logreg(self, trial):\n",
    "        penalty = trial.suggest_categorical(\"penalty\", [None, \"l1\", \"l2\", \"elasticnet\"])\n",
    "        logreg_c = trial.suggest_int(\"logreg_c\", 1, 100)\n",
    "\n",
    "        if penalty == \"elasticnet\":\n",
    "            l1_ratio = trial.suggest_float(\"l1_ratio\", 0, 1)\n",
    "            clf = LogisticRegression(\n",
    "                random_state=self.random_state,\n",
    "                n_jobs=self.n_jobs,\n",
    "                penalty=penalty,\n",
    "                C=logreg_c,\n",
    "                l1_ratio=l1_ratio,\n",
    "                solver=\"saga\",\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            clf = LogisticRegression(\n",
    "                random_state=self.random_state,\n",
    "                n_jobs=self.n_jobs,\n",
    "                penalty=penalty,\n",
    "                C=logreg_c,\n",
    "                solver=\"saga\",\n",
    "            )\n",
    "\n",
    "        return clf\n",
    "\n",
    "    def __model_rf(self, trial):\n",
    "        # bootstrap = trial.suggest_categorical(\"bootstrap\", [True, False])\n",
    "        # max_sample = None\n",
    "        # if bootstrap:\n",
    "        #     max_sample = trial.suggest_float(\"max_samples\", 0, 1)\n",
    "\n",
    "        return RandomForestClassifier(\n",
    "            random_state=self.random_state,\n",
    "            n_jobs=self.n_jobs,\n",
    "\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 100, 4e3),\n",
    "            max_depth=trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            min_samples_split=trial.suggest_float(\"min_samples_split\", 0, 0.5),\n",
    "            min_samples_leaf=trial.suggest_float(\"min_samples_leaf\", 0, 0.3),\n",
    "            min_weight_fraction_leaf=trial.suggest_float(\"min_weight_fraction_leaf\", 0, 0.3),\n",
    "            max_features=trial.suggest_float(\"max_features\", 0, 1),\n",
    "            # max_leaf_nodes=trial.suggest_int(\"mlf\", 0, 5e3),\n",
    "            # min_impurity_decrease=trial.suggest_float(\"min_impurity_decrease\", 0, 5e3),\n",
    "            # bootstrap=bootstrap,\n",
    "            # warm_start=trial.suggest_categorical(\"warm_start\", [True, False]),\n",
    "            # max_samples=max_sample,\n",
    "            # ccp_alpha=trial.suggest_float(\"ccp_alpha\", 0, 5e3),\n",
    "        )\n",
    "\n",
    "    def __model_xgb(self, trial):\n",
    "        return xgboost.XGBClassifier(\n",
    "            enable_categorical=True,\n",
    "            random_state=self.random_state,\n",
    "            n_jobs=self.n_jobs,\n",
    "\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 1, 1e4),\n",
    "            eta=trial.suggest_float(\"eta\", 0.01, 1),\n",
    "            gamma=trial.suggest_float(\"gamma\", 0, 20),\n",
    "            max_depth=trial.suggest_int(\"max_depth\", 3, 10, step=1),\n",
    "            max_leaves=trial.suggest_int(\"max_leaves\", 0, 1e4),\n",
    "            colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.05, 1),\n",
    "            colsample_bylevel=trial.suggest_float(\"colsample_bylevel\", 0.05, 1),\n",
    "            colsample_bynode=trial.suggest_float(\"colsample_bynode\", 0.05, 1),\n",
    "            reg_lambda=trial.suggest_int(\"reg_lambda\", 0, 20),\n",
    "            reg_alpha=trial.suggest_int(\"reg_alpha\", 0, 20),\n",
    "            grow_policy=trial.suggest_categorical(\n",
    "                \"grow_policy\", [\"depthwise\", \"lossguide\"]\n",
    "            ),\n",
    "            min_child_weight=trial.suggest_float(\"min_child_weight\", 0, 1e3),\n",
    "            max_delta_step=trial.suggest_float(\"max_delta_step\", 0, 1e2)\n",
    "        )\n",
    "\n",
    "    def __aug_rfe(self, trial, steps, clf, total_feats, use_rfe):\n",
    "        if use_rfe:\n",
    "            n_features_to_select = trial.suggest_float(\"rfe_n_features_to_select\", 0, 1)\n",
    "            if int(n_features_to_select * total_feats) <= 0:\n",
    "                n_features_to_select = 1\n",
    "\n",
    "            steps.append(\n",
    "                (\n",
    "                    \"model\",\n",
    "                    RFE(\n",
    "                        clf,\n",
    "                        n_features_to_select=n_features_to_select,\n",
    "                        # step=trial.suggest_float(\"rfe_step\", 0, 1),\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            steps.append((\"model\", clf))\n",
    "\n",
    "    def __preproc_polyfeats(self, trial, low_degree=1, high_degree=2):\n",
    "        return PolynomialFeatures(\n",
    "            trial.suggest_int(\"poly_feats_degrees\", low_degree, high_degree)\n",
    "        )\n",
    "\n",
    "    def __preproc_standardscaler(self):\n",
    "        return StandardScaler()\n",
    "\n",
    "    def __preproc_robustscaler(self, trial):\n",
    "        return RobustScaler(\n",
    "            with_centering=trial.suggest_categorical(\"with_centering\", [True, False]),\n",
    "            with_scaling=trial.suggest_categorical(\"with_scaling\", [True, False]),\n",
    "        )\n",
    "\n",
    "    def preprocess(self, trial, inp_df):\n",
    "        if trial.suggest_categorical(\"include_orig\", [True, False]):\n",
    "            inp_df = self.__include_orig(inp_df)\n",
    "        if trial.suggest_categorical(\"prune_low_freq\", [True, False]):\n",
    "            inp_df = self.__prune_low_freq(inp_df)\n",
    "        if trial.suggest_categorical(\"prune_low_importance\", [True, False]):\n",
    "            inp_df = self.__prune_low_importance(trial, inp_df)\n",
    "\n",
    "        x = inp_df.drop(columns=[\"Target\"])\n",
    "        y = self.label_encoder.fit_transform(inp_df[\"Target\"])\n",
    "\n",
    "        remaining_feats = set(x.columns)\n",
    "        cont_cols = [\n",
    "            x.columns.get_loc(c) for c in remaining_feats.difference(cat_features)\n",
    "        ]\n",
    "        cat_cols = [\n",
    "            x.columns.get_loc(c) for c in remaining_feats.difference(cont_features)\n",
    "        ]\n",
    "\n",
    "        numerical_pipeline = Pipeline([])\n",
    "\n",
    "        if trial.suggest_categorical(\"poly_feats\", [True, False]):\n",
    "            poly_feats = self.__preproc_polyfeats(trial)\n",
    "            numerical_pipeline.steps.append((\"poly_feats\", poly_feats))\n",
    "\n",
    "        if trial.suggest_categorical(\"use_standardscaler\", [True, False]):\n",
    "            standard_scaler = self.__preproc_standardscaler()\n",
    "            numerical_pipeline.steps.append((\"standard_scaler\", standard_scaler))\n",
    "\n",
    "        if trial.suggest_categorical(\"use_robustscaler\", [True, False]):\n",
    "            robust_scaler = self.__preproc_robustscaler(trial)\n",
    "            numerical_pipeline.steps.append((\"robust_scaler\", robust_scaler))\n",
    "\n",
    "        col_transformer = None\n",
    "        if len(numerical_pipeline.steps) > 0:\n",
    "            col_transformer = ColumnTransformer(\n",
    "                [(\"numerical_pipeline\", numerical_pipeline, cont_cols)],\n",
    "                remainder=\"passthrough\",\n",
    "            )\n",
    "\n",
    "        if col_transformer:\n",
    "            x = col_transformer.fit_transform(x)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def init_model(self, trial):\n",
    "        clf_selector = {\n",
    "            \"logreg\": self.__model_logreg,\n",
    "            \"random_forest\": self.__model_rf,\n",
    "            \"xgboost\": self.__model_xgb,\n",
    "        }\n",
    "\n",
    "        return clf_selector[\n",
    "            trial.suggest_categorical(\n",
    "                \"classifier\", [\"logreg\"]\n",
    "            )\n",
    "        ](trial)\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        train_df = self.train.copy()\n",
    "\n",
    "        x, y = self.preprocess(trial, train_df)\n",
    "        model = self.init_model(trial)\n",
    "\n",
    "        scores = cross_val_score(\n",
    "            model,\n",
    "            x,\n",
    "            y,\n",
    "            scoring=make_scorer(accuracy_score),\n",
    "            cv=self.kfold,\n",
    "            n_jobs=self.n_jobs,\n",
    "            error_score=\"raise\",\n",
    "        )\n",
    "\n",
    "        return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-17 17:43:13,144] Using an existing study with name 'aug_logreg_v2' instead of creating a new one.\n",
      "[I 2024-06-17 17:44:28,699] Trial 54 finished with value: 0.8158342097745426 and parameters: {'include_orig': False, 'prune_low_freq': False, 'prune_low_importance': False, 'poly_feats': True, 'poly_feats_degrees': 2, 'use_standardscaler': False, 'use_robustscaler': False, 'classifier': 'logreg', 'penalty': 'l1', 'logreg_c': 28}. Best is trial 40 with value: 0.8158342097745426.\n",
      "[I 2024-06-17 17:45:45,128] Trial 55 finished with value: 0.8158342097745426 and parameters: {'include_orig': False, 'prune_low_freq': False, 'prune_low_importance': False, 'poly_feats': True, 'poly_feats_degrees': 2, 'use_standardscaler': False, 'use_robustscaler': False, 'classifier': 'logreg', 'penalty': 'l1', 'logreg_c': 33}. Best is trial 40 with value: 0.8158342097745426.\n",
      "[I 2024-06-17 17:47:00,381] Trial 56 finished with value: 0.8158342097745426 and parameters: {'include_orig': False, 'prune_low_freq': False, 'prune_low_importance': False, 'poly_feats': True, 'poly_feats_degrees': 2, 'use_standardscaler': False, 'use_robustscaler': False, 'classifier': 'logreg', 'penalty': 'l1', 'logreg_c': 29}. Best is trial 40 with value: 0.8158342097745426.\n",
      "[I 2024-06-17 17:48:15,848] Trial 57 finished with value: 0.8158342097745426 and parameters: {'include_orig': False, 'prune_low_freq': False, 'prune_low_importance': False, 'poly_feats': True, 'poly_feats_degrees': 2, 'use_standardscaler': False, 'use_robustscaler': False, 'classifier': 'logreg', 'penalty': 'l1', 'logreg_c': 44}. Best is trial 40 with value: 0.8158342097745426.\n",
      "[I 2024-06-17 17:48:25,062] Trial 58 finished with value: 0.719791442176281 and parameters: {'include_orig': False, 'prune_low_freq': False, 'prune_low_importance': False, 'poly_feats': False, 'use_standardscaler': False, 'use_robustscaler': False, 'classifier': 'logreg', 'penalty': 'l1', 'logreg_c': 75}. Best is trial 40 with value: 0.8158342097745426.\n",
      "[I 2024-06-17 17:49:41,847] Trial 59 finished with value: 0.8158342097745426 and parameters: {'include_orig': False, 'prune_low_freq': False, 'prune_low_importance': False, 'poly_feats': True, 'poly_feats_degrees': 2, 'use_standardscaler': False, 'use_robustscaler': False, 'classifier': 'logreg', 'penalty': 'l1', 'logreg_c': 35}. Best is trial 40 with value: 0.8158342097745426.\n",
      "[I 2024-06-17 17:50:56,757] Trial 60 finished with value: 0.8158342097745426 and parameters: {'include_orig': False, 'prune_low_freq': False, 'prune_low_importance': False, 'poly_feats': True, 'poly_feats_degrees': 2, 'use_standardscaler': False, 'use_robustscaler': False, 'classifier': 'logreg', 'penalty': 'l1', 'logreg_c': 24}. Best is trial 40 with value: 0.8158342097745426.\n",
      "[I 2024-06-17 17:52:12,050] Trial 61 finished with value: 0.8158342097745426 and parameters: {'include_orig': False, 'prune_low_freq': False, 'prune_low_importance': False, 'poly_feats': True, 'poly_feats_degrees': 2, 'use_standardscaler': False, 'use_robustscaler': False, 'classifier': 'logreg', 'penalty': 'elasticnet', 'logreg_c': 43, 'l1_ratio': 0.047260835088347664}. Best is trial 40 with value: 0.8158342097745426.\n",
      "[I 2024-06-17 17:53:26,453] Trial 62 finished with value: 0.8158342097745426 and parameters: {'include_orig': False, 'prune_low_freq': False, 'prune_low_importance': False, 'poly_feats': True, 'poly_feats_degrees': 2, 'use_standardscaler': False, 'use_robustscaler': False, 'classifier': 'logreg', 'penalty': 'l1', 'logreg_c': 25}. Best is trial 40 with value: 0.8158342097745426.\n",
      "[I 2024-06-17 17:54:42,457] Trial 63 finished with value: 0.8158342097745426 and parameters: {'include_orig': False, 'prune_low_freq': False, 'prune_low_importance': False, 'poly_feats': True, 'poly_feats_degrees': 2, 'use_standardscaler': False, 'use_robustscaler': False, 'classifier': 'logreg', 'penalty': 'l1', 'logreg_c': 100}. Best is trial 40 with value: 0.8158342097745426.\n",
      "[I 2024-06-17 17:55:56,584] Trial 64 finished with value: 0.8158342097745426 and parameters: {'include_orig': False, 'prune_low_freq': False, 'prune_low_importance': False, 'poly_feats': True, 'poly_feats_degrees': 2, 'use_standardscaler': False, 'use_robustscaler': False, 'classifier': 'logreg', 'penalty': 'l1', 'logreg_c': 34}. Best is trial 40 with value: 0.8158342097745426.\n",
      "[I 2024-06-17 17:57:11,536] Trial 65 finished with value: 0.8158342097745426 and parameters: {'include_orig': False, 'prune_low_freq': False, 'prune_low_importance': False, 'poly_feats': True, 'poly_feats_degrees': 2, 'use_standardscaler': False, 'use_robustscaler': False, 'classifier': 'logreg', 'penalty': 'l1', 'logreg_c': 24}. Best is trial 40 with value: 0.8158342097745426.\n",
      "[I 2024-06-17 17:58:24,362] Trial 66 finished with value: 0.8158342097745426 and parameters: {'include_orig': False, 'prune_low_freq': False, 'prune_low_importance': False, 'poly_feats': True, 'poly_feats_degrees': 2, 'use_standardscaler': False, 'use_robustscaler': False, 'classifier': 'logreg', 'penalty': 'l1', 'logreg_c': 5}. Best is trial 40 with value: 0.8158342097745426.\n",
      "[I 2024-06-17 17:59:39,981] Trial 67 finished with value: 0.8158342097745426 and parameters: {'include_orig': False, 'prune_low_freq': False, 'prune_low_importance': False, 'poly_feats': True, 'poly_feats_degrees': 2, 'use_standardscaler': False, 'use_robustscaler': False, 'classifier': 'logreg', 'penalty': 'l1', 'logreg_c': 28}. Best is trial 40 with value: 0.8158342097745426.\n",
      "[W 2024-06-17 18:00:19,385] Trial 68 failed with parameters: {'include_orig': False, 'prune_low_freq': False, 'prune_low_importance': False, 'poly_feats': True, 'poly_feats_degrees': 2, 'use_standardscaler': False, 'use_robustscaler': False, 'classifier': 'logreg', 'penalty': 'l1', 'logreg_c': 60} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Programming\\Languages\\Python Venvs\\dgl_torchgeo\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Cyr\\AppData\\Local\\Temp\\ipykernel_5436\\2041854166.py\", line 272, in __call__\n",
      "    scores = cross_val_score(\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programming\\Languages\\Python Venvs\\dgl_torchgeo\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 562, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "                 ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programming\\Languages\\Python Venvs\\dgl_torchgeo\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programming\\Languages\\Python Venvs\\dgl_torchgeo\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 309, in cross_validate\n",
      "    results = parallel(\n",
      "              ^^^^^^^^^\n",
      "  File \"d:\\Programming\\Languages\\Python Venvs\\dgl_torchgeo\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Programming\\Languages\\Python Venvs\\dgl_torchgeo\\Lib\\site-packages\\joblib\\parallel.py\", line 1952, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"d:\\Programming\\Languages\\Python Venvs\\dgl_torchgeo\\Lib\\site-packages\\joblib\\parallel.py\", line 1595, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"d:\\Programming\\Languages\\Python Venvs\\dgl_torchgeo\\Lib\\site-packages\\joblib\\parallel.py\", line 1707, in _retrieve\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n",
      "[W 2024-06-17 18:00:19,386] Trial 68 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 20\u001b[0m\n\u001b[0;32m     12\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[0;32m     13\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///optuna.sqlite3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maug_logreg_v2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     18\u001b[0m objective \u001b[38;5;241m=\u001b[39m ObjectiveCV(train_df, original_df, crossval_kf, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[1;32md:\\Programming\\Languages\\Python Venvs\\dgl_torchgeo\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Programming\\Languages\\Python Venvs\\dgl_torchgeo\\Lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32md:\\Programming\\Languages\\Python Venvs\\dgl_torchgeo\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32md:\\Programming\\Languages\\Python Venvs\\dgl_torchgeo\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32md:\\Programming\\Languages\\Python Venvs\\dgl_torchgeo\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[27], line 272\u001b[0m, in \u001b[0;36mObjectiveCV.__call__\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    269\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(trial, train_df)\n\u001b[0;32m    270\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_model(trial)\n\u001b[1;32m--> 272\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43maccuracy_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraise\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(scores)\n",
      "File \u001b[1;32md:\\Programming\\Languages\\Python Venvs\\dgl_torchgeo\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Programming\\Languages\\Python Venvs\\dgl_torchgeo\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32md:\\Programming\\Languages\\Python Venvs\\dgl_torchgeo\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Programming\\Languages\\Python Venvs\\dgl_torchgeo\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Programming\\Languages\\Python Venvs\\dgl_torchgeo\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32md:\\Programming\\Languages\\Python Venvs\\dgl_torchgeo\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Programming\\Languages\\Python Venvs\\dgl_torchgeo\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "crossval_kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# optuna.delete_study(study_name=\"aug_rf_v1\", storage=\"sqlite:///optuna.sqlite3\")\n",
    "\n",
    "# study = optuna.create_study(\n",
    "#     direction=\"maximize\",\n",
    "#     storage=\"sqlite:///optuna.sqlite3\",\n",
    "#     study_name=\"classifiers_simple\",\n",
    "#     load_if_exists=True\n",
    "# )\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    storage=\"sqlite:///optuna.sqlite3\",\n",
    "    study_name=\"aug_logreg_v2\",\n",
    "    load_if_exists=True\n",
    ")\n",
    "objective = ObjectiveCV(train_df, original_df, crossval_kf, n_jobs=8)\n",
    "\n",
    "study.optimize(objective, n_trials=50)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'include_orig': False,\n",
       " 'prune_low_freq': False,\n",
       " 'prune_low_importance': True,\n",
       " 'prune_thresh': 0.011,\n",
       " 'classifier': 'logreg',\n",
       " 'penalty': 'l2',\n",
       " 'logreg_c': 7}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = make_pipeline(\n",
    "#                 StandardScaler(),\n",
    "#                 xgboost.XGBClassifier(enable_categorical=True, random_state=0, n_jobs=-1,\n",
    "#                     eta=study.best_params[\"eta\"],\n",
    "#                     gamma=study.best_params[\"gamma\"],\n",
    "#                     max_depth=study.best_params[\"max_depth\"],\n",
    "#                     col_sample_bytree=study.best_params[\"col_sample_bytree\"],\n",
    "#                     col_sample_bylevel=study.best_params[\"col_sample_bylevel\"],\n",
    "#                     col_sample_bynode=study.best_params[\"col_sample_bynode\"],\n",
    "#                     reg_lambda=study.best_params[\"reg_lambda\"],\n",
    "#                     reg_alpha=study.best_params[\"reg_alpha\"],\n",
    "#                     grow_policy=study.best_params[\"grow_policy\"],\n",
    "#                     device=\"cuda\"\n",
    "#                 )\n",
    "#             )\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# targets = label_encoder.fit_transform(train_df[\"Target\"])\n",
    "# orig_targets = label_encoder.transform(original_df[\"Target\"])\n",
    "\n",
    "# combined_features = pd.concat([train_df[train_features], original_df[train_features]], axis=0)\n",
    "# combined_targets = np.hstack([targets, orig_targets]) \n",
    "\n",
    "# best_model.fit(combined_features, combined_targets)\n",
    "# test_preds = best_model.predict(test_df[train_features])\n",
    "\n",
    "# out_pd = test_df.copy(deep=True)\n",
    "# out_pd[\"Target\"] = label_encoder.inverse_transform(test_preds)\n",
    "\n",
    "# out_pd.to_csv(\"optuna_model.csv\", columns=[\"Target\"], index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importances = best_model[1].feature_importances_\n",
    "# rf_importances = pd.Series(importances, index=train_features)\n",
    "# rf_importances = rf_importances.sort_values(ascending=False)\n",
    "# rf_importances = rf_importances[rf_importances > 0]\n",
    "\n",
    "# print(rf_importances.to_string())\n",
    "\n",
    "# sns.barplot(x=rf_importances.index, y=rf_importances.values, hue=rf_importances.index, legend=False)\n",
    "# plt.title('XGB Feature importances')\n",
    "# plt.ylabel('Mean decrease in impurity')\n",
    "# plt.xticks(rotation=45, ha=\"right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenc = LabelEncoder()\n",
    "# x = train_df.drop(columns=[\"Target\"])\n",
    "# y = lenc.fit_transform(train_df[\"Target\"])\n",
    "\n",
    "# test_trans = ColumnTransformer(\n",
    "#     [(\"standardscaler\", StandardScaler(), train_features)], remainder=\"passthrough\"\n",
    "# )\n",
    "# pipeline = Pipeline(\n",
    "#     [\n",
    "#         (\n",
    "#             \"polyfeats_transformer\",\n",
    "#             ColumnTransformer(\n",
    "#                 [\n",
    "#                     (\n",
    "#                         \"polyfeats\",\n",
    "#                         PolynomialFeatures(2),\n",
    "#                         x.columns,\n",
    "#                     )\n",
    "#                 ],\n",
    "#                 remainder=\"passthrough\",\n",
    "#             ),\n",
    "#         ),\n",
    "#         # (\"trans\", test_trans),\n",
    "#         # (\"model\", xgboost.XGBClassifier()),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# print(pipeline)\n",
    "\n",
    "\n",
    "# # cross_val_score(pipeline, x, y, scoring=make_scorer(accuracy_score), n_jobs=-1)\n",
    "# pipeline.fit(x)\n",
    "# pipeline[0].transformers[0][1].get_feature_names_out(x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_val, y_train, y_val = train_test_split(train_df.drop(columns=[\"Target\"]),  train_df[\"Target\"])\n",
    "\n",
    "# test_model = RandomForestClassifier(n_jobs=-1)\n",
    "# test_model.fit(x_train, y_train)\n",
    "# preds = test_model.predict(x_val)\n",
    "# sum(np.equal(preds, y_val)) / len(preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl_torchgeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
