{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import umap\n",
    "import datetime\n",
    "import optuna\n",
    "import pprint\n",
    "import joblib\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, label_binarize, PolynomialFeatures, RobustScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import r2_score, accuracy_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import xgboost\n",
    "\n",
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\", index_col=0)\n",
    "test_df = pd.read_csv(\"data/test.csv\", index_col=0)\n",
    "original_df = pd.read_csv(\"data/original.csv\",sep=\";\")\n",
    "train_features = test_df.columns\n",
    "\n",
    "cat_features = ['Marital status', 'Application mode', \"Application order\", 'Course', \"Daytime/evening attendance\",\n",
    "                'Previous qualification', 'Nacionality', \"Mother's qualification\", \n",
    "                \"Father's qualification\", \"Mother's occupation\",\n",
    "                \"Father's occupation\", \"Displaced\", \"Educational special needs\", \"Debtor\", \"Tuition fees up to date\",\n",
    "                \"Gender\", \"Scholarship holder\", \"International\"]\n",
    "cont_features = [feature for feature in train_features if feature not in cat_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in cat_features:\n",
    "    dtype = pd.CategoricalDtype(categories=list(set(train_df[feat]) | set(test_df[feat]) | set(original_df[feat])), ordered=False)\n",
    "    for df in [train_df, test_df, original_df]:\n",
    "        df[feat] = df[feat].astype(dtype)\n",
    "\n",
    "combined_df = pd.concat([train_df, original_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240618_230351\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240618_230351\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.11.1\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       13.70 GB / 31.93 GB (42.9%)\n",
      "Disk Space Avail:   584.44 GB / 1863.00 GB (31.4%)\n",
      "===================================================\n",
      "Train Data Rows:    76518\n",
      "Train Data Columns: 36\n",
      "Label Column:       Target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t3 unique label values:  ['Graduate', 'Dropout', 'Enrolled']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14023.17 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.42 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  9 | ['Marital status', 'Application mode', 'Course', 'Previous qualification', 'Nacionality', ...]\n",
      "\t\t('float', [])    :  7 | ['Previous qualification (grade)', 'Admission grade', 'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)', 'Unemployment rate', ...]\n",
      "\t\t('int', [])      : 20 | ['Application order', 'Daytime/evening attendance', 'Displaced', 'Educational special needs', 'Debtor', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  9 | ['Marital status', 'Application mode', 'Course', 'Previous qualification', 'Nacionality', ...]\n",
      "\t\t('float', [])     :  7 | ['Previous qualification (grade)', 'Admission grade', 'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)', 'Unemployment rate', ...]\n",
      "\t\t('int', [])       : 12 | ['Application order', 'Age at enrollment', 'Curricular units 1st sem (credited)', 'Curricular units 1st sem (enrolled)', 'Curricular units 1st sem (evaluations)', ...]\n",
      "\t\t('int', ['bool']) :  8 | ['Daytime/evening attendance', 'Displaced', 'Educational special needs', 'Debtor', 'Tuition fees up to date', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t36 features in original data used to generate 36 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 12.34 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.03267205102067487, Train Rows: 74018, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.7652\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.7656\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 7: early stopping\n",
      "\t0.8268\t = Validation score   (accuracy)\n",
      "\t60.08s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.8308\t = Validation score   (accuracy)\n",
      "\t1.47s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.8312\t = Validation score   (accuracy)\n",
      "\t1.81s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.8228\t = Validation score   (accuracy)\n",
      "\t6.64s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.8216\t = Validation score   (accuracy)\n",
      "\t6.91s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.8264\t = Validation score   (accuracy)\n",
      "\t66.62s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.8228\t = Validation score   (accuracy)\n",
      "\t4.23s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.8232\t = Validation score   (accuracy)\n",
      "\t4.44s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.8304\t = Validation score   (accuracy)\n",
      "\t2.58s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.8192\t = Validation score   (accuracy)\n",
      "\t91.42s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.824\t = Validation score   (accuracy)\n",
      "\t1.44s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'LightGBM': 0.923, 'CatBoost': 0.077}\n",
      "\t0.8316\t = Validation score   (accuracy)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 250.95s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240618_230351\")\n"
     ]
    }
   ],
   "source": [
    "train_data = TabularDataset(train_df)\n",
    "test_data = TabularDataset(test_df)\n",
    "\n",
    "predictor = TabularPredictor(label=\"Target\").fit(train_data=train_data)\n",
    "predictions = predictor.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pd = pd.DataFrame(index=test_df.index)\n",
    "out_pd[\"Target\"] = list(predictions)\n",
    "out_pd.to_csv(\"autogluon_no_orig.csv\", columns=[\"Target\"], index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240618_231136\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240618_231136\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.11.1\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       13.77 GB / 31.93 GB (43.1%)\n",
      "Disk Space Avail:   581.81 GB / 1863.00 GB (31.2%)\n",
      "===================================================\n",
      "Train Data Rows:    80942\n",
      "Train Data Columns: 36\n",
      "Label Column:       Target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t3 unique label values:  ['Graduate', 'Dropout', 'Enrolled']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14101.97 MB\n",
      "\tTrain Data (Original)  Memory Usage: 17.37 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  9 | ['Marital status', 'Application mode', 'Course', 'Previous qualification', 'Nacionality', ...]\n",
      "\t\t('float', [])    :  7 | ['Previous qualification (grade)', 'Admission grade', 'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)', 'Unemployment rate', ...]\n",
      "\t\t('int', [])      : 20 | ['Application order', 'Daytime/evening attendance', 'Displaced', 'Educational special needs', 'Debtor', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  9 | ['Marital status', 'Application mode', 'Course', 'Previous qualification', 'Nacionality', ...]\n",
      "\t\t('float', [])     :  7 | ['Previous qualification (grade)', 'Admission grade', 'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)', 'Unemployment rate', ...]\n",
      "\t\t('int', [])       : 12 | ['Application order', 'Age at enrollment', 'Curricular units 1st sem (credited)', 'Curricular units 1st sem (enrolled)', 'Curricular units 1st sem (evaluations)', ...]\n",
      "\t\t('int', ['bool']) :  8 | ['Daytime/evening attendance', 'Displaced', 'Educational special needs', 'Debtor', 'Tuition fees up to date', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t36 features in original data used to generate 36 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 13.05 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.030886313656692446, Train Rows: 78442, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.768\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.7684\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.8328\t = Validation score   (accuracy)\n",
      "\t73.42s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.8272\t = Validation score   (accuracy)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.836\t = Validation score   (accuracy)\n",
      "\t1.76s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.83\t = Validation score   (accuracy)\n",
      "\t7.36s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.8272\t = Validation score   (accuracy)\n",
      "\t7.86s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.8284\t = Validation score   (accuracy)\n",
      "\t25.63s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.8308\t = Validation score   (accuracy)\n",
      "\t4.89s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.8324\t = Validation score   (accuracy)\n",
      "\t5.15s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.8368\t = Validation score   (accuracy)\n",
      "\t3.64s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.8316\t = Validation score   (accuracy)\n",
      "\t75.14s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.8332\t = Validation score   (accuracy)\n",
      "\t1.57s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'XGBoost': 0.6, 'NeuralNetTorch': 0.4}\n",
      "\t0.8392\t = Validation score   (accuracy)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 210.75s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240618_231136\")\n"
     ]
    }
   ],
   "source": [
    "train_data = TabularDataset(combined_df)\n",
    "test_data = TabularDataset(test_df)\n",
    "\n",
    "predictor = TabularPredictor(label=\"Target\").fit(train_data=train_data)\n",
    "predictions = predictor.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pd = pd.DataFrame(index=test_df.index)\n",
    "out_pd[\"Target\"] = list(predictions)\n",
    "out_pd.to_csv(\"autogluon.csv\", columns=[\"Target\"], index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"AutogluonModels/misc/\"\n",
      "Presets specified: ['medium_quality']\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (80942 samples, 867.92 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/misc/\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.11.1\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       17.48 GB / 31.93 GB (54.7%)\n",
      "Disk Space Avail:   561.55 GB / 1863.00 GB (30.1%)\n",
      "===================================================\n",
      "Train Data Rows:    80942\n",
      "Train Data Columns: 1348\n",
      "Label Column:       Target\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t3 unique label values:  ['Graduate', 'Dropout', 'Enrolled']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17883.87 MB\n",
      "\tTrain Data (Original)  Memory Usage: 822.72 MB (4.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 8 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   18 | ['Marital status', 'Application mode', 'Application order', 'Course', 'Daytime/evening attendance', ...]\n",
      "\t\t('float', [])    : 1329 | ['Previous qualification (grade)', 'Admission grade', 'Age at enrollment', 'Curricular units 1st sem (credited)', 'Curricular units 1st sem (enrolled)', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :   10 | ['Marital status', 'Application mode', 'Application order', 'Course', 'Previous qualification', ...]\n",
      "\t\t('float', [])     : 1329 | ['Previous qualification (grade)', 'Admission grade', 'Age at enrollment', 'Curricular units 1st sem (credited)', 'Curricular units 1st sem (enrolled)', ...]\n",
      "\t\t('int', ['bool']) :    8 | ['Daytime/evening attendance', 'Displaced', 'Educational special needs', 'Debtor', 'Tuition fees up to date', ...]\n",
      "\t6.0s = Fit runtime\n",
      "\t1347 features in original data used to generate 1347 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 822.10 MB (4.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 6.8s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.030886313656692446, Train Rows: 78442, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.7616\t = Validation score   (accuracy)\n",
      "\t3.77s\t = Training   runtime\n",
      "\t2.67s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.7624\t = Validation score   (accuracy)\n",
      "\t2.15s\t = Training   runtime\n",
      "\t2.66s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.8356\t = Validation score   (accuracy)\n",
      "\t167.27s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.838\t = Validation score   (accuracy)\n",
      "\t51.47s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.8376\t = Validation score   (accuracy)\n",
      "\t32.6s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.8116\t = Validation score   (accuracy)\n",
      "\t69.69s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.812\t = Validation score   (accuracy)\n",
      "\t65.25s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tMany features detected (1347), dynamically setting 'colsample_bylevel' to 0.7423904974016332 to speed up training (Default = 1).\n",
      "\tTo disable this functionality, explicitly specify 'colsample_bylevel' in the model hyperparameters.\n",
      "\t0.828\t = Validation score   (accuracy)\n",
      "\t127.97s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.8128\t = Validation score   (accuracy)\n",
      "\t35.64s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.8108\t = Validation score   (accuracy)\n",
      "\t33.8s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.8388\t = Validation score   (accuracy)\n",
      "\t45.51s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.832\t = Validation score   (accuracy)\n",
      "\t335.53s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.8392\t = Validation score   (accuracy)\n",
      "\t79.23s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'LightGBMLarge': 0.5, 'NeuralNetFastAI': 0.25, 'RandomForestGini': 0.125, 'ExtraTreesGini': 0.125}\n",
      "\t0.8432\t = Validation score   (accuracy)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1067.14s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/misc/\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AutogluonModels/misc/poly_feats.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_feats = PolynomialFeatures(3)\n",
    "\n",
    "train_cont = combined_df[cont_features]\n",
    "test_cont = test_df[cont_features]\n",
    "\n",
    "poly_train = poly_feats.fit_transform(train_cont)\n",
    "poly_train = pd.DataFrame(poly_train, index=train_cont.index, columns=poly_feats.get_feature_names_out())\n",
    "\n",
    "poly_test = poly_feats.transform(test_cont)\n",
    "poly_test = pd.DataFrame(poly_test, index=test_cont.index, columns=poly_feats.get_feature_names_out())\n",
    "\n",
    "train_data = combined_df.drop(columns=cont_features)\n",
    "train_data = pd.concat([train_data, poly_train], axis=1)\n",
    "test_data = test_df.drop(columns=cont_features)\n",
    "test_data = pd.concat([test_data, poly_test], axis=1)\n",
    "\n",
    "train_data = TabularDataset(train_data)\n",
    "test_data = TabularDataset(test_data)\n",
    "\n",
    "predictor = TabularPredictor(label=\"Target\", path=\"AutogluonModels/ag-misc/\").fit(train_data=train_data, presets=\"medium_quality\")\n",
    "predictions = predictor.predict(test_data)\n",
    "\n",
    "joblib.dump(poly_feats, \"AutogluonModels/misc/poly_feats.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['1']\n",
      "Computing feature importance via permutation shuffling for 1347 features using 5000 rows with 5 shuffle sets...\n",
      "\t8749.23s\t= Expected runtime (1749.85s per shuffle set)\n",
      "\t4314.18s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    }
   ],
   "source": [
    "feature_importances = predictor.feature_importance(train_data)\n",
    "feature_importances.to_csv(\"ag_feature_importances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pd = pd.DataFrame(index=test_df.index)\n",
    "out_pd[\"Target\"] = list(predictions)\n",
    "out_pd.to_csv(\"autogluon_poly_orig.csv\", columns=[\"Target\"], index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl_torchgeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
